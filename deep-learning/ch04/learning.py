"""
学習
ここでは訓練データから最適な重みパラメータの値を自動で取得することを指す。

損失関数という指標を導入する。
損失関数を基準として、その値が最も小さくなる重みパラメータを探し出すということが学習の目的
この章では勾配法を解説

「５」という数字を認識するプログラムをどうやって実装するか？
特徴量を抽出して、その特徴量のパターンを機械学習の技術で学習する方法が考えられる。
特徴量とは、入力データ（入力画像）から本質的なデータ（重要なデータ）を的確に抽出できるように設計された変換器を指す。
画像の特徴量は通常ベクトルとして記述される。

コンピュータービジョンの分野で有名な特徴量
SIFT、SURF、HOGなど
変換されたベクトルに対して、機械学習で使われる識別器
SVM、KNNなど
集められたデータの中から機械が規則性を見つけ出す。

特徴量は人が設計したものであることに注意
問題に応じて適切な特徴量を使わないとなかなか良い結果が得られない。

ニューラルネットワークは特徴量も機械が学習する end to end
"""

# coding: utf-8
import numpy as np

def mean_squared_error(y, t):
    return 0.5 * np.sum((y - t)**2)

# t = [0, 0, 1, 0, 0, 0, 0, 0 ,0 ,0] # 「2」を正解とする
# # 例１：「2」の確率が最も高い場合(0.6)　正解の場合
# y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
# print(mean_squared_error(np.array(y), np.array(t)))

# # 例１：「7」の確率が最も高い場合(0.6)ハズレ
# y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
# print(mean_squared_error(np.array(y), np.array(t)))

# y = [0.0, 0.05, 0.1, 0.1, 0.05, 0.1, 0.0, 0.1, 0.5, 0.0]
# print(mean_squared_error(np.array(y), np.array(t)))

# 交差エントロピー誤差
def cross_entropy_error(y ,t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))

t = [0, 0, 1, 0, 0, 0, 0, 0 ,0 ,0] # 「2」を正解とする
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
print(cross_entropy_error(np.array(y), np.array(t)))

y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]
print(cross_entropy_error(np.array(y), np.array(t)))

y = [0.0, 0.05, 0.9, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]
print(cross_entropy_error(np.array(y), np.array(t)))