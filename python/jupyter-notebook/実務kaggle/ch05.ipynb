{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba690ac-c895-40c7-99e4-8e307aaba975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: LightGBM in /opt/anaconda3/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from LightGBM) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from LightGBM) (1.13.1)\n",
      "Requirement already satisfied: japanize-matplotlib in /opt/anaconda3/lib/python3.12/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from japanize-matplotlib) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import ydata_profiling as ypf\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# モデリング\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "!pip install LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pip install japanize-matplotlib\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02f3e26-87b0-452e-8081-8000a182a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "x_train, y_train, id_train = df_train[['Pclass', 'Fare']], df_train[['Survived']], df_train[['PassengerId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e94d3c-2b43-4ca9-be9a-f3537ae805c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル学習、評価を関数化する\n",
    "\n",
    "# ハイパーパラメータ\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metrics': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'n_estimators': 100000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "def train_cv(input_x, input_y, input_id, params, n_split=5):\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    \n",
    "    n_splits = 5\n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    \n",
    "    for nfold in np.arange(n_splits):\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "    \n",
    "        model = lgb.LGBMClassifier(**params, force_row_wise=True)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr),(x_va, y_va)],\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True),lgb.log_evaluation(1)]\n",
    "                 )\n",
    "        y_tr_pred = model.predict(x_tr)\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "        metric_va = accuracy_score(y_va, y_va_pred)\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        _imp = pd.DataFrame({'col': x_train.columns, \"imp\": model.feature_importances_})\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "    \n",
    "    print('-'*20, 'result', '-'*20)\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "\n",
    "    print('[cv ] tr: {:.2f}+-{:.2f}, va:{:.2f}+-{:.2f}'.format(\n",
    "        metrics[:,1].mean(),metrics[:,1].std(),\n",
    "        metrics[:,2].mean(),metrics[:,1].std(),\n",
    "    ))\n",
    "    imp = imp.groupby('col')['imp'].agg(['mean','std'])\n",
    "    imp.columns = ['imp','imp_std']\n",
    "    imp = imp.reset_index(drop=False)\n",
    "\n",
    "    return imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5d42dd-e05e-4ada-852f-cd3f227fbd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 123\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "[1]\ttraining's auc: 0.762985\tvalid_1's auc: 0.729381\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.763607\tvalid_1's auc: 0.730237\n",
      "[3]\ttraining's auc: 0.763607\tvalid_1's auc: 0.730237\n",
      "[4]\ttraining's auc: 0.777045\tvalid_1's auc: 0.732411\n",
      "[5]\ttraining's auc: 0.775702\tvalid_1's auc: 0.735046\n",
      "[6]\ttraining's auc: 0.777383\tvalid_1's auc: 0.72747\n",
      "[7]\ttraining's auc: 0.774955\tvalid_1's auc: 0.738274\n",
      "[8]\ttraining's auc: 0.776974\tvalid_1's auc: 0.739394\n",
      "[9]\ttraining's auc: 0.780612\tvalid_1's auc: 0.729644\n",
      "[10]\ttraining's auc: 0.788155\tvalid_1's auc: 0.736957\n",
      "[11]\ttraining's auc: 0.792636\tvalid_1's auc: 0.739723\n",
      "[12]\ttraining's auc: 0.793779\tvalid_1's auc: 0.740382\n",
      "[13]\ttraining's auc: 0.793958\tvalid_1's auc: 0.735903\n",
      "[14]\ttraining's auc: 0.794342\tvalid_1's auc: 0.737088\n",
      "[15]\ttraining's auc: 0.795168\tvalid_1's auc: 0.738603\n",
      "[16]\ttraining's auc: 0.800733\tvalid_1's auc: 0.735705\n",
      "[17]\ttraining's auc: 0.801868\tvalid_1's auc: 0.732345\n",
      "[18]\ttraining's auc: 0.803391\tvalid_1's auc: 0.731094\n",
      "[19]\ttraining's auc: 0.805331\tvalid_1's auc: 0.733663\n",
      "[20]\ttraining's auc: 0.805606\tvalid_1's auc: 0.731686\n",
      "[21]\ttraining's auc: 0.806311\tvalid_1's auc: 0.734321\n",
      "[22]\ttraining's auc: 0.807521\tvalid_1's auc: 0.735903\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.793779\tvalid_1's auc: 0.740382\n",
      "-------------------- 1 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 123\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.763368\tvalid_1's auc: 0.725802\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.767704\tvalid_1's auc: 0.736832\n",
      "[3]\ttraining's auc: 0.769092\tvalid_1's auc: 0.730548\n",
      "[4]\ttraining's auc: 0.770622\tvalid_1's auc: 0.733155\n",
      "[5]\ttraining's auc: 0.77206\tvalid_1's auc: 0.741444\n",
      "[6]\ttraining's auc: 0.772056\tvalid_1's auc: 0.735294\n",
      "[7]\ttraining's auc: 0.779392\tvalid_1's auc: 0.738503\n",
      "[8]\ttraining's auc: 0.778736\tvalid_1's auc: 0.74385\n",
      "[9]\ttraining's auc: 0.784796\tvalid_1's auc: 0.749198\n",
      "[10]\ttraining's auc: 0.786679\tvalid_1's auc: 0.74873\n",
      "[11]\ttraining's auc: 0.788941\tvalid_1's auc: 0.747527\n",
      "[12]\ttraining's auc: 0.78993\tvalid_1's auc: 0.745254\n",
      "[13]\ttraining's auc: 0.793954\tvalid_1's auc: 0.747193\n",
      "[14]\ttraining's auc: 0.793733\tvalid_1's auc: 0.746257\n",
      "[15]\ttraining's auc: 0.794116\tvalid_1's auc: 0.751805\n",
      "[16]\ttraining's auc: 0.796589\tvalid_1's auc: 0.750401\n",
      "[17]\ttraining's auc: 0.797986\tvalid_1's auc: 0.750802\n",
      "[18]\ttraining's auc: 0.799108\tvalid_1's auc: 0.752406\n",
      "[19]\ttraining's auc: 0.799145\tvalid_1's auc: 0.751404\n",
      "[20]\ttraining's auc: 0.800014\tvalid_1's auc: 0.752874\n",
      "[21]\ttraining's auc: 0.800571\tvalid_1's auc: 0.754612\n",
      "[22]\ttraining's auc: 0.801851\tvalid_1's auc: 0.753409\n",
      "[23]\ttraining's auc: 0.803286\tvalid_1's auc: 0.756083\n",
      "[24]\ttraining's auc: 0.804208\tvalid_1's auc: 0.757019\n",
      "[25]\ttraining's auc: 0.804799\tvalid_1's auc: 0.757019\n",
      "[26]\ttraining's auc: 0.807006\tvalid_1's auc: 0.757219\n",
      "[27]\ttraining's auc: 0.807563\tvalid_1's auc: 0.75635\n",
      "[28]\ttraining's auc: 0.808436\tvalid_1's auc: 0.755949\n",
      "[29]\ttraining's auc: 0.808486\tvalid_1's auc: 0.757152\n",
      "[30]\ttraining's auc: 0.808685\tvalid_1's auc: 0.755214\n",
      "[31]\ttraining's auc: 0.809774\tvalid_1's auc: 0.754545\n",
      "[32]\ttraining's auc: 0.80999\tvalid_1's auc: 0.752941\n",
      "[33]\ttraining's auc: 0.810007\tvalid_1's auc: 0.751604\n",
      "[34]\ttraining's auc: 0.810194\tvalid_1's auc: 0.752674\n",
      "[35]\ttraining's auc: 0.811175\tvalid_1's auc: 0.752139\n",
      "[36]\ttraining's auc: 0.811167\tvalid_1's auc: 0.75254\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.807006\tvalid_1's auc: 0.757219\n",
      "-------------------- 2 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.773099\tvalid_1's auc: 0.696791\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.773423\tvalid_1's auc: 0.700201\n",
      "[3]\ttraining's auc: 0.77344\tvalid_1's auc: 0.701003\n",
      "[4]\ttraining's auc: 0.774118\tvalid_1's auc: 0.701671\n",
      "[5]\ttraining's auc: 0.778071\tvalid_1's auc: 0.713302\n",
      "[6]\ttraining's auc: 0.778677\tvalid_1's auc: 0.713235\n",
      "[7]\ttraining's auc: 0.779654\tvalid_1's auc: 0.714439\n",
      "[8]\ttraining's auc: 0.779193\tvalid_1's auc: 0.715241\n",
      "[9]\ttraining's auc: 0.780594\tvalid_1's auc: 0.714037\n",
      "[10]\ttraining's auc: 0.784015\tvalid_1's auc: 0.716243\n",
      "[11]\ttraining's auc: 0.785482\tvalid_1's auc: 0.717112\n",
      "[12]\ttraining's auc: 0.788695\tvalid_1's auc: 0.715575\n",
      "[13]\ttraining's auc: 0.792403\tvalid_1's auc: 0.717848\n",
      "[14]\ttraining's auc: 0.79631\tvalid_1's auc: 0.721123\n",
      "[15]\ttraining's auc: 0.797907\tvalid_1's auc: 0.720187\n",
      "[16]\ttraining's auc: 0.798829\tvalid_1's auc: 0.71885\n",
      "[17]\ttraining's auc: 0.800226\tvalid_1's auc: 0.721858\n",
      "[18]\ttraining's auc: 0.801748\tvalid_1's auc: 0.721992\n",
      "[19]\ttraining's auc: 0.803277\tvalid_1's auc: 0.722928\n",
      "[20]\ttraining's auc: 0.8041\tvalid_1's auc: 0.725401\n",
      "[21]\ttraining's auc: 0.808003\tvalid_1's auc: 0.723797\n",
      "[22]\ttraining's auc: 0.807679\tvalid_1's auc: 0.726738\n",
      "[23]\ttraining's auc: 0.80866\tvalid_1's auc: 0.725936\n",
      "[24]\ttraining's auc: 0.812647\tvalid_1's auc: 0.725668\n",
      "[25]\ttraining's auc: 0.813079\tvalid_1's auc: 0.726471\n",
      "[26]\ttraining's auc: 0.813968\tvalid_1's auc: 0.732086\n",
      "[27]\ttraining's auc: 0.814376\tvalid_1's auc: 0.731818\n",
      "[28]\ttraining's auc: 0.817003\tvalid_1's auc: 0.723396\n",
      "[29]\ttraining's auc: 0.818711\tvalid_1's auc: 0.729078\n",
      "[30]\ttraining's auc: 0.819451\tvalid_1's auc: 0.729412\n",
      "[31]\ttraining's auc: 0.82064\tvalid_1's auc: 0.73008\n",
      "[32]\ttraining's auc: 0.821176\tvalid_1's auc: 0.726738\n",
      "[33]\ttraining's auc: 0.821559\tvalid_1's auc: 0.726003\n",
      "[34]\ttraining's auc: 0.822037\tvalid_1's auc: 0.724799\n",
      "[35]\ttraining's auc: 0.822244\tvalid_1's auc: 0.725334\n",
      "[36]\ttraining's auc: 0.822594\tvalid_1's auc: 0.726805\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.813968\tvalid_1's auc: 0.732086\n",
      "-------------------- 3 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 124\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.770252\tvalid_1's auc: 0.71738\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.771191\tvalid_1's auc: 0.718717\n",
      "[3]\ttraining's auc: 0.772151\tvalid_1's auc: 0.717647\n",
      "[4]\ttraining's auc: 0.773806\tvalid_1's auc: 0.714037\n",
      "[5]\ttraining's auc: 0.778046\tvalid_1's auc: 0.712701\n",
      "[6]\ttraining's auc: 0.777389\tvalid_1's auc: 0.715508\n",
      "[7]\ttraining's auc: 0.778611\tvalid_1's auc: 0.718449\n",
      "[8]\ttraining's auc: 0.781658\tvalid_1's auc: 0.719586\n",
      "[9]\ttraining's auc: 0.784705\tvalid_1's auc: 0.723596\n",
      "[10]\ttraining's auc: 0.786322\tvalid_1's auc: 0.725602\n",
      "[11]\ttraining's auc: 0.78771\tvalid_1's auc: 0.727206\n",
      "[12]\ttraining's auc: 0.788766\tvalid_1's auc: 0.735561\n",
      "[13]\ttraining's auc: 0.792195\tvalid_1's auc: 0.737233\n",
      "[14]\ttraining's auc: 0.792719\tvalid_1's auc: 0.736832\n",
      "[15]\ttraining's auc: 0.794515\tvalid_1's auc: 0.739639\n",
      "[16]\ttraining's auc: 0.796473\tvalid_1's auc: 0.742848\n",
      "[17]\ttraining's auc: 0.796755\tvalid_1's auc: 0.742714\n",
      "[18]\ttraining's auc: 0.800255\tvalid_1's auc: 0.749933\n",
      "[19]\ttraining's auc: 0.80075\tvalid_1's auc: 0.754345\n",
      "[20]\ttraining's auc: 0.802383\tvalid_1's auc: 0.751604\n",
      "[21]\ttraining's auc: 0.803065\tvalid_1's auc: 0.754813\n",
      "[22]\ttraining's auc: 0.803381\tvalid_1's auc: 0.75615\n",
      "[23]\ttraining's auc: 0.80462\tvalid_1's auc: 0.756952\n",
      "[24]\ttraining's auc: 0.807093\tvalid_1's auc: 0.754479\n",
      "[25]\ttraining's auc: 0.807621\tvalid_1's auc: 0.754746\n",
      "[26]\ttraining's auc: 0.807571\tvalid_1's auc: 0.754746\n",
      "[27]\ttraining's auc: 0.807467\tvalid_1's auc: 0.75635\n",
      "[28]\ttraining's auc: 0.808756\tvalid_1's auc: 0.757821\n",
      "[29]\ttraining's auc: 0.81093\tvalid_1's auc: 0.754947\n",
      "[30]\ttraining's auc: 0.811753\tvalid_1's auc: 0.754813\n",
      "[31]\ttraining's auc: 0.811707\tvalid_1's auc: 0.756016\n",
      "[32]\ttraining's auc: 0.813511\tvalid_1's auc: 0.754545\n",
      "[33]\ttraining's auc: 0.814143\tvalid_1's auc: 0.75508\n",
      "[34]\ttraining's auc: 0.813503\tvalid_1's auc: 0.754679\n",
      "[35]\ttraining's auc: 0.814604\tvalid_1's auc: 0.755348\n",
      "[36]\ttraining's auc: 0.814006\tvalid_1's auc: 0.755882\n",
      "[37]\ttraining's auc: 0.815232\tvalid_1's auc: 0.754746\n",
      "[38]\ttraining's auc: 0.814625\tvalid_1's auc: 0.754345\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.808756\tvalid_1's auc: 0.757821\n",
      "-------------------- 4 --------------------\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 118\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "[1]\ttraining's auc: 0.755436\tvalid_1's auc: 0.749834\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.758558\tvalid_1's auc: 0.758077\n",
      "[3]\ttraining's auc: 0.759844\tvalid_1's auc: 0.759673\n",
      "[4]\ttraining's auc: 0.761684\tvalid_1's auc: 0.747972\n",
      "[5]\ttraining's auc: 0.7624\tvalid_1's auc: 0.745446\n",
      "[6]\ttraining's auc: 0.765414\tvalid_1's auc: 0.744316\n",
      "[7]\ttraining's auc: 0.765414\tvalid_1's auc: 0.744316\n",
      "[8]\ttraining's auc: 0.770409\tvalid_1's auc: 0.744914\n",
      "[9]\ttraining's auc: 0.772815\tvalid_1's auc: 0.74538\n",
      "[10]\ttraining's auc: 0.775008\tvalid_1's auc: 0.745911\n",
      "[11]\ttraining's auc: 0.779096\tvalid_1's auc: 0.744848\n",
      "[12]\ttraining's auc: 0.783017\tvalid_1's auc: 0.749368\n",
      "[13]\ttraining's auc: 0.783808\tvalid_1's auc: 0.747773\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.759844\tvalid_1's auc: 0.759673\n",
      "-------------------- result --------------------\n",
      "[[0.         0.72050562 0.67597765]\n",
      " [1.         0.75175316 0.67977528]\n",
      " [2.         0.75315568 0.6741573 ]\n",
      " [3.         0.74614306 0.69101124]\n",
      " [4.         0.6171108  0.61235955]]\n",
      "[cv ] tr: 0.72+-0.05, va:0.67+-0.05\n"
     ]
    }
   ],
   "source": [
    "imp, metrics = train_cv(x_train, y_train, id_train, params, n_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46abce5-8cfd-49fd-bc47-5eaf0c74f0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "[1]\ttraining's auc: 0.782093\tvalid_1's auc: 0.657708\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.795214\tvalid_1's auc: 0.669236\n",
      "[3]\ttraining's auc: 0.805598\tvalid_1's auc: 0.67859\n",
      "[4]\ttraining's auc: 0.810237\tvalid_1's auc: 0.674045\n",
      "[5]\ttraining's auc: 0.809636\tvalid_1's auc: 0.676943\n",
      "[6]\ttraining's auc: 0.822132\tvalid_1's auc: 0.696904\n",
      "[7]\ttraining's auc: 0.825949\tvalid_1's auc: 0.704743\n",
      "[8]\ttraining's auc: 0.82743\tvalid_1's auc: 0.701383\n",
      "[9]\ttraining's auc: 0.828135\tvalid_1's auc: 0.703755\n",
      "[10]\ttraining's auc: 0.834706\tvalid_1's auc: 0.700264\n",
      "[11]\ttraining's auc: 0.839153\tvalid_1's auc: 0.699736\n",
      "[12]\ttraining's auc: 0.840522\tvalid_1's auc: 0.704348\n",
      "[13]\ttraining's auc: 0.842729\tvalid_1's auc: 0.704348\n",
      "[14]\ttraining's auc: 0.844823\tvalid_1's auc: 0.705138\n",
      "[15]\ttraining's auc: 0.846408\tvalid_1's auc: 0.708564\n",
      "[16]\ttraining's auc: 0.848757\tvalid_1's auc: 0.706192\n",
      "[17]\ttraining's auc: 0.849792\tvalid_1's auc: 0.707642\n",
      "[18]\ttraining's auc: 0.852345\tvalid_1's auc: 0.710408\n",
      "[19]\ttraining's auc: 0.853839\tvalid_1's auc: 0.710672\n",
      "[20]\ttraining's auc: 0.85567\tvalid_1's auc: 0.712451\n",
      "[21]\ttraining's auc: 0.857548\tvalid_1's auc: 0.716008\n",
      "[22]\ttraining's auc: 0.859738\tvalid_1's auc: 0.718445\n",
      "[23]\ttraining's auc: 0.862583\tvalid_1's auc: 0.71693\n",
      "[24]\ttraining's auc: 0.863764\tvalid_1's auc: 0.719433\n",
      "[25]\ttraining's auc: 0.865337\tvalid_1's auc: 0.718379\n",
      "[26]\ttraining's auc: 0.867289\tvalid_1's auc: 0.721871\n",
      "[27]\ttraining's auc: 0.868165\tvalid_1's auc: 0.725033\n",
      "[28]\ttraining's auc: 0.870923\tvalid_1's auc: 0.7222\n",
      "[29]\ttraining's auc: 0.872487\tvalid_1's auc: 0.723123\n",
      "[30]\ttraining's auc: 0.87421\tvalid_1's auc: 0.726285\n",
      "[31]\ttraining's auc: 0.876497\tvalid_1's auc: 0.723386\n",
      "[32]\ttraining's auc: 0.878291\tvalid_1's auc: 0.724835\n",
      "[33]\ttraining's auc: 0.879847\tvalid_1's auc: 0.722991\n",
      "[34]\ttraining's auc: 0.880423\tvalid_1's auc: 0.720356\n",
      "[35]\ttraining's auc: 0.881486\tvalid_1's auc: 0.721476\n",
      "[36]\ttraining's auc: 0.88278\tvalid_1's auc: 0.721739\n",
      "[37]\ttraining's auc: 0.883789\tvalid_1's auc: 0.720817\n",
      "[38]\ttraining's auc: 0.885053\tvalid_1's auc: 0.719895\n",
      "[39]\ttraining's auc: 0.885517\tvalid_1's auc: 0.723847\n",
      "[40]\ttraining's auc: 0.887181\tvalid_1's auc: 0.722398\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.87421\tvalid_1's auc: 0.726285\n",
      "-------------------- 1 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.787735\tvalid_1's auc: 0.732152\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.801868\tvalid_1's auc: 0.730414\n",
      "[3]\ttraining's auc: 0.803369\tvalid_1's auc: 0.724131\n",
      "[4]\ttraining's auc: 0.810306\tvalid_1's auc: 0.734158\n",
      "[5]\ttraining's auc: 0.808552\tvalid_1's auc: 0.727139\n",
      "[6]\ttraining's auc: 0.813366\tvalid_1's auc: 0.733289\n",
      "[7]\ttraining's auc: 0.819547\tvalid_1's auc: 0.73984\n",
      "[8]\ttraining's auc: 0.826314\tvalid_1's auc: 0.739171\n",
      "[9]\ttraining's auc: 0.830196\tvalid_1's auc: 0.740709\n",
      "[10]\ttraining's auc: 0.83237\tvalid_1's auc: 0.744987\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[12]\ttraining's auc: 0.838107\tvalid_1's auc: 0.741711\n",
      "[13]\ttraining's auc: 0.839462\tvalid_1's auc: 0.742914\n",
      "[14]\ttraining's auc: 0.842825\tvalid_1's auc: 0.74365\n",
      "[15]\ttraining's auc: 0.845165\tvalid_1's auc: 0.74258\n",
      "[16]\ttraining's auc: 0.847031\tvalid_1's auc: 0.738503\n",
      "[17]\ttraining's auc: 0.847858\tvalid_1's auc: 0.743249\n",
      "[18]\ttraining's auc: 0.848224\tvalid_1's auc: 0.745321\n",
      "[19]\ttraining's auc: 0.849621\tvalid_1's auc: 0.743249\n",
      "[20]\ttraining's auc: 0.852127\tvalid_1's auc: 0.74365\n",
      "[21]\ttraining's auc: 0.853466\tvalid_1's auc: 0.741845\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "-------------------- 2 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.785241\tvalid_1's auc: 0.752473\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.798368\tvalid_1's auc: 0.754813\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[4]\ttraining's auc: 0.812447\tvalid_1's auc: 0.764906\n",
      "[5]\ttraining's auc: 0.815498\tvalid_1's auc: 0.762834\n",
      "[6]\ttraining's auc: 0.81746\tvalid_1's auc: 0.754278\n",
      "[7]\ttraining's auc: 0.817988\tvalid_1's auc: 0.756283\n",
      "[8]\ttraining's auc: 0.820183\tvalid_1's auc: 0.758021\n",
      "[9]\ttraining's auc: 0.824414\tvalid_1's auc: 0.759024\n",
      "[10]\ttraining's auc: 0.827835\tvalid_1's auc: 0.761297\n",
      "[11]\ttraining's auc: 0.831768\tvalid_1's auc: 0.75635\n",
      "[12]\ttraining's auc: 0.833763\tvalid_1's auc: 0.752072\n",
      "[13]\ttraining's auc: 0.835139\tvalid_1's auc: 0.758757\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "-------------------- 3 --------------------\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "[1]\ttraining's auc: 0.79991\tvalid_1's auc: 0.694652\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.79991\tvalid_1's auc: 0.694652\n",
      "[3]\ttraining's auc: 0.812065\tvalid_1's auc: 0.706417\n",
      "[4]\ttraining's auc: 0.814908\tvalid_1's auc: 0.710762\n",
      "[5]\ttraining's auc: 0.814534\tvalid_1's auc: 0.711765\n",
      "[6]\ttraining's auc: 0.82293\tvalid_1's auc: 0.725067\n",
      "[7]\ttraining's auc: 0.829037\tvalid_1's auc: 0.736765\n",
      "[8]\ttraining's auc: 0.832063\tvalid_1's auc: 0.733957\n",
      "[9]\ttraining's auc: 0.835845\tvalid_1's auc: 0.733623\n",
      "[10]\ttraining's auc: 0.836398\tvalid_1's auc: 0.73389\n",
      "[11]\ttraining's auc: 0.838423\tvalid_1's auc: 0.732955\n",
      "[12]\ttraining's auc: 0.840892\tvalid_1's auc: 0.734492\n",
      "[13]\ttraining's auc: 0.841648\tvalid_1's auc: 0.736832\n",
      "[14]\ttraining's auc: 0.842521\tvalid_1's auc: 0.740174\n",
      "[15]\ttraining's auc: 0.846212\tvalid_1's auc: 0.744318\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[17]\ttraining's auc: 0.848923\tvalid_1's auc: 0.747059\n",
      "[18]\ttraining's auc: 0.850003\tvalid_1's auc: 0.746591\n",
      "[19]\ttraining's auc: 0.850386\tvalid_1's auc: 0.746457\n",
      "[20]\ttraining's auc: 0.852659\tvalid_1's auc: 0.746457\n",
      "[21]\ttraining's auc: 0.853333\tvalid_1's auc: 0.74619\n",
      "[22]\ttraining's auc: 0.854364\tvalid_1's auc: 0.745922\n",
      "[23]\ttraining's auc: 0.856317\tvalid_1's auc: 0.74639\n",
      "[24]\ttraining's auc: 0.857178\tvalid_1's auc: 0.743249\n",
      "[25]\ttraining's auc: 0.857623\tvalid_1's auc: 0.743583\n",
      "[26]\ttraining's auc: 0.859248\tvalid_1's auc: 0.74004\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "-------------------- 4 --------------------\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "[1]\ttraining's auc: 0.771645\tvalid_1's auc: 0.730156\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.801041\tvalid_1's auc: 0.756016\n",
      "[3]\ttraining's auc: 0.802077\tvalid_1's auc: 0.764194\n",
      "[4]\ttraining's auc: 0.811047\tvalid_1's auc: 0.758077\n",
      "[5]\ttraining's auc: 0.811235\tvalid_1's auc: 0.753357\n",
      "[6]\ttraining's auc: 0.820047\tvalid_1's auc: 0.757745\n",
      "[7]\ttraining's auc: 0.82751\tvalid_1's auc: 0.760936\n",
      "[8]\ttraining's auc: 0.827697\tvalid_1's auc: 0.762532\n",
      "[9]\ttraining's auc: 0.830998\tvalid_1's auc: 0.768249\n",
      "[10]\ttraining's auc: 0.833616\tvalid_1's auc: 0.768382\n",
      "[11]\ttraining's auc: 0.834257\tvalid_1's auc: 0.766919\n",
      "[12]\ttraining's auc: 0.836289\tvalid_1's auc: 0.766387\n",
      "[13]\ttraining's auc: 0.836334\tvalid_1's auc: 0.764526\n",
      "[14]\ttraining's auc: 0.838616\tvalid_1's auc: 0.768781\n",
      "[15]\ttraining's auc: 0.840343\tvalid_1's auc: 0.76898\n",
      "[16]\ttraining's auc: 0.842532\tvalid_1's auc: 0.769911\n",
      "[17]\ttraining's auc: 0.84376\tvalid_1's auc: 0.768781\n",
      "[18]\ttraining's auc: 0.847249\tvalid_1's auc: 0.768249\n",
      "[19]\ttraining's auc: 0.85035\tvalid_1's auc: 0.767983\n",
      "[20]\ttraining's auc: 0.851053\tvalid_1's auc: 0.764991\n",
      "[21]\ttraining's auc: 0.85226\tvalid_1's auc: 0.768249\n",
      "[22]\ttraining's auc: 0.85462\tvalid_1's auc: 0.766122\n",
      "[23]\ttraining's auc: 0.857505\tvalid_1's auc: 0.764659\n",
      "[24]\ttraining's auc: 0.8587\tvalid_1's auc: 0.766454\n",
      "[25]\ttraining's auc: 0.860415\tvalid_1's auc: 0.771639\n",
      "[26]\ttraining's auc: 0.862092\tvalid_1's auc: 0.772437\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[28]\ttraining's auc: 0.865784\tvalid_1's auc: 0.773567\n",
      "[29]\ttraining's auc: 0.866525\tvalid_1's auc: 0.771108\n",
      "[30]\ttraining's auc: 0.867341\tvalid_1's auc: 0.770975\n",
      "[31]\ttraining's auc: 0.869218\tvalid_1's auc: 0.770975\n",
      "[32]\ttraining's auc: 0.871133\tvalid_1's auc: 0.769047\n",
      "[33]\ttraining's auc: 0.872619\tvalid_1's auc: 0.767451\n",
      "[34]\ttraining's auc: 0.873676\tvalid_1's auc: 0.769977\n",
      "[35]\ttraining's auc: 0.875183\tvalid_1's auc: 0.769977\n",
      "[36]\ttraining's auc: 0.876931\tvalid_1's auc: 0.768382\n",
      "[37]\ttraining's auc: 0.879254\tvalid_1's auc: 0.769047\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "-------------------- result --------------------\n",
      "[[0.         0.78230337 0.69832402]\n",
      " [1.         0.75736325 0.71910112]\n",
      " [2.         0.7026648  0.65730337]\n",
      " [3.         0.76858345 0.6741573 ]\n",
      " [4.         0.7769986  0.71348315]]\n",
      "[cv ] tr: 0.76+-0.03, va:0.69+-0.03\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train[['Pclass', 'Fare', 'Age']]\n",
    "imp, metrics = train_cv(x_train, y_train, id_train, params, n_split=5)\n",
    "#  → tr: 0.76+-0.03, va:0.69+-0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75dd828-6c18-418f-8d33-6d11af2acb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376d3292-a815-498a-83e8-30b720d5d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>891</td>\n",
       "      <td>681</td>\n",
       "      <td>347082</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>204</td>\n",
       "      <td>147</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                      top freq\n",
       "Name       891    891  Braund, Mr. Owen Harris    1\n",
       "Sex        891      2                     male  577\n",
       "Ticket     891    681                   347082    7\n",
       "Cabin      204    147                  B96 B98    4\n",
       "Embarked   889      3                        S  644"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(exclude='number').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f94200-2f59-41d5-ad0f-3fda7c0c0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypf.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966c8437-d6f5-4e55-8944-90edd97a53d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.42\n",
       "max    80.00\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Age'].agg(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407333f9-a653-41c0-9735-4b6948a3a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['Age'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c012452b-efed-4bd9-83e2-40e2dafb4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "四分位範囲 17.875\n",
      "下限値 -6.6875\n",
      "上限値 64.8125\n"
     ]
    }
   ],
   "source": [
    "# 外れ値検出\n",
    "quantile = df_train['Age'].quantile(q=0.75) - df_train['Age'].quantile(q=0.25)\n",
    "print('四分位範囲', quantile)\n",
    "print('下限値', df_train['Age'].quantile(q=0.25) - quantile * 1.5)\n",
    "print('上限値', df_train['Age'].quantile(q=0.75) + quantile * 1.5)\n",
    "\n",
    "# 推定だから間違っている可能性もあるので注意。無闇に適用しないこと。モデルの精度が上がらない場合やデータの異常が考えられるが他の方法で外れ値が検出できない場合などに使う。ｎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a3656-b7f7-476a-b16b-757409dcc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "特徴量選択の方法\n",
    "    フィルター法：データセットのみ見て判断する方法。目的変数と特徴量１つずつの関係を評価して、有効性の有無を判定する。\n",
    "    ラッパー法　：特徴量をモデルのみに適用してみて、モデルの精度の良し悪しから特徴量の有効性を判断する。\n",
    "    組み込み法　：モデルの学習時に、同時に特徴量の選択を行う方法。→Lasso回帰が有名\n",
    "\n",
    "    おすすめはラッパー法。モデルによって特徴量の捉え方が異なるので、作成した特徴量を適用したときのモデルの精度で判断する方法が良いと考える。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ea4f158-4b94-4c1d-a1bd-eba850db7275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "186634fb-7333-44d1-bd78-3391a89e7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# ハイパーパラメータ\n",
    "params_base = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metrics': 'auc',\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    'bagging_freq': 1,\n",
    "    'seed': 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    params_tuning = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 200),\n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-5, 1e-2, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-2, 1e2, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "\n",
    "    list_metrics = []\n",
    "\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    \n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "    \n",
    "        model = lgb.LGBMClassifier(**params, force_row_wise=True)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr),(x_va, y_va)],\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "                 )\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred >= 0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "    return np.mean(list_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd5486e3-1e53-4994-8b28-f0c23b5277ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:13,156] A new study created in memory with name: no-name-1605abfc-1c09-4169-bc42-965e8ad4c8a3\n",
      "[I 2024-12-29 22:23:13,367] Trial 0 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.49252223377910603, 'lambda_l2': 83.76388146302452}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:13,914] Trial 1 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.5679223741740078, 'lambda_l2': 0.01732652966363563}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:14,289] Trial 2 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102121, 'lambda_l2': 3.448290408913144}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:14,573] Trial 3 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.27999780223990095, 'lambda_l2': 0.08185645330667264}. Best is trial 0 with value: 0.6935911116690728.\n",
      "[I 2024-12-29 22:23:14,765] Trial 4 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751795, 'lambda_l2': 0.5050346330980693}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:14,959] Trial 5 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:15,151] Trial 6 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659083, 'lambda_l2': 1.1965765212602308}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:15,339] Trial 7 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:15,598] Trial 8 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.2067148127117098, 'lambda_l2': 3.1594683442464047}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:15,786] Trial 9 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641546}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:15,982] Trial 10 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 29, 'min_sum_hessian_in_leaf': 0.00010530695817517065, 'feature_fraction': 0.5040305717020104, 'bagging_fraction': 0.9940542446575643, 'lambda_l1': 0.010612397212799442, 'lambda_l2': 67.10287596337035}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:16,197] Trial 11 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 245, 'min_data_in_leaf': 59, 'min_sum_hessian_in_leaf': 0.00019952242350034497, 'feature_fraction': 0.680510676303443, 'bagging_fraction': 0.9046129327183772, 'lambda_l1': 13.55100815052138, 'lambda_l2': 85.35741664238788}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:16,423] Trial 12 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 188, 'min_data_in_leaf': 57, 'min_sum_hessian_in_leaf': 7.659182988788056e-05, 'feature_fraction': 0.6570923224140477, 'bagging_fraction': 0.8899780780638389, 'lambda_l1': 0.14501718610211514, 'lambda_l2': 0.010232463153115963}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:16,626] Trial 13 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 144, 'min_data_in_leaf': 109, 'min_sum_hessian_in_leaf': 0.0006630877110584158, 'feature_fraction': 0.837025122599692, 'bagging_fraction': 0.5430552645659706, 'lambda_l1': 0.033837657134204495, 'lambda_l2': 16.048872499864505}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:16,807] Trial 14 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 204, 'min_data_in_leaf': 5, 'min_sum_hessian_in_leaf': 5.717717987936209e-05, 'feature_fraction': 0.5578428743173742, 'bagging_fraction': 0.9478369458173551, 'lambda_l1': 7.792559440024684, 'lambda_l2': 14.048839041680221}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:17,003] Trial 15 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 243, 'min_data_in_leaf': 67, 'min_sum_hessian_in_leaf': 0.00033040787452620027, 'feature_fraction': 0.7495517698115405, 'bagging_fraction': 0.8413048560197381, 'lambda_l1': 0.5860216156613824, 'lambda_l2': 0.2927113532128868}. Best is trial 0 with value: 0.6935911116690728.\n",
      "[I 2024-12-29 22:23:17,192] Trial 16 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 136, 'min_data_in_leaf': 112, 'min_sum_hessian_in_leaf': 0.00018784164693824454, 'feature_fraction': 0.9863422835511906, 'bagging_fraction': 0.851410424861598, 'lambda_l1': 6.236338820604067, 'lambda_l2': 12.68845523919227}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:17,376] Trial 17 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 203, 'min_data_in_leaf': 84, 'min_sum_hessian_in_leaf': 1.158042029894523e-05, 'feature_fraction': 0.9197171562685666, 'bagging_fraction': 0.9323606407970545, 'lambda_l1': 38.23011167780388, 'lambda_l2': 0.04837506886369723}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:17,569] Trial 18 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 166, 'min_data_in_leaf': 192, 'min_sum_hessian_in_leaf': 0.0013206936578061411, 'feature_fraction': 0.7982392212545764, 'bagging_fraction': 0.8127751519094408, 'lambda_l1': 0.07579790826497941, 'lambda_l2': 0.01188874797017692}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:17,766] Trial 19 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 26, 'min_data_in_leaf': 42, 'min_sum_hessian_in_leaf': 3.562764976211569e-05, 'feature_fraction': 0.70468696257256, 'bagging_fraction': 0.9938187588498407, 'lambda_l1': 0.48279881650982936, 'lambda_l2': 6.549199908903182}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:17,968] Trial 20 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 225, 'min_data_in_leaf': 101, 'min_sum_hessian_in_leaf': 0.00012900355443870758, 'feature_fraction': 0.6402149158291418, 'bagging_fraction': 0.8866299986002277, 'lambda_l1': 0.018991646784323135, 'lambda_l2': 26.431339754051077}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:18,157] Trial 21 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 158, 'min_sum_hessian_in_leaf': 3.593271863664184e-05, 'feature_fraction': 0.6051287052482378, 'bagging_fraction': 0.7832506732776294, 'lambda_l1': 1.6514000298458829, 'lambda_l2': 4.156916351584709}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:18,368] Trial 22 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 57, 'min_data_in_leaf': 185, 'min_sum_hessian_in_leaf': 4.362576016235821e-05, 'feature_fraction': 0.5744796213142894, 'bagging_fraction': 0.6704793574378827, 'lambda_l1': 0.9856756213569424, 'lambda_l2': 0.6302264257303645}. Best is trial 0 with value: 0.6935911116690728.\n",
      "[I 2024-12-29 22:23:18,555] Trial 23 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 120, 'min_data_in_leaf': 123, 'min_sum_hessian_in_leaf': 2.310098438235442e-05, 'feature_fraction': 0.5102400853215387, 'bagging_fraction': 0.8072607134383624, 'lambda_l1': 0.46111813747377395, 'lambda_l2': 45.191827331891616}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:18,747] Trial 24 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 145, 'min_data_in_leaf': 74, 'min_sum_hessian_in_leaf': 0.0003762233937533676, 'feature_fraction': 0.5658698695392914, 'bagging_fraction': 0.7026983677031235, 'lambda_l1': 3.5952552526826915, 'lambda_l2': 0.1556293360755586}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:18,936] Trial 25 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 187, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 7.768365379969924e-05, 'feature_fraction': 0.7485826141312114, 'bagging_fraction': 0.8658752226638118, 'lambda_l1': 0.1300014137742713, 'lambda_l2': 6.892890525418996}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:19,125] Trial 26 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 154, 'min_data_in_leaf': 168, 'min_sum_hessian_in_leaf': 1.0080282578342995e-05, 'feature_fraction': 0.6748099499133925, 'bagging_fraction': 0.931597560015761, 'lambda_l1': 1.3198505214286191, 'lambda_l2': 1.5309771162083439}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:19,318] Trial 27 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 46, 'min_sum_hessian_in_leaf': 0.00016695591142069498, 'feature_fraction': 0.5997291251136706, 'bagging_fraction': 0.8031630721757818, 'lambda_l1': 0.25427390969124913, 'lambda_l2': 31.54508096515745}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:19,505] Trial 28 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 126, 'min_data_in_leaf': 122, 'min_sum_hessian_in_leaf': 6.8305100303546e-05, 'feature_fraction': 0.7919753394873922, 'bagging_fraction': 0.5898177727170965, 'lambda_l1': 13.611257110413906, 'lambda_l2': 0.023063221163797425}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
      "[LightGBM] [Info] Start training from score -0.475028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.913235\tvalid_1's auc: 0.72892\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.837591\tvalid_1's auc: 0.745856\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.811104\tvalid_1's auc: 0.768249\n",
      "[LightGBM] [Info] Number of positive: 274, number of negative: 439\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384292 -> initscore=-0.471371\n",
      "[LightGBM] [Info] Start training from score -0.471371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.847634\tvalid_1's auc: 0.747326\n",
      "[LightGBM] [Info] Number of positive: 273, number of negative: 440\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 713, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382889 -> initscore=-0.477303\n",
      "[LightGBM] [Info] Start training from score -0.477303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 22:23:19,683] Trial 29 finished with value: 0.6935911116690728 and parameters: {'num_leaves': 222, 'min_data_in_leaf': 143, 'min_sum_hessian_in_leaf': 0.0007084761848130609, 'feature_fraction': 0.7208079207745085, 'bagging_fraction': 0.6770145123660526, 'lambda_l1': 0.6880424935145814, 'lambda_l2': 0.07964791320835117}. Best is trial 0 with value: 0.6935911116690728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.864011\tvalid_1's auc: 0.775961\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9f2c8dd-abe3-406f-921f-00000030651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.6936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 181,\n",
       " 'min_data_in_leaf': 61,\n",
       " 'min_sum_hessian_in_leaf': 4.792414358623587e-05,\n",
       " 'feature_fraction': 0.7756573845414456,\n",
       " 'bagging_fraction': 0.8597344848927815,\n",
       " 'lambda_l1': 0.49252223377910603,\n",
       " 'lambda_l2': 83.76388146302452}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2fbeec3-7edb-4cb8-a0ef-ff5a0c2ac2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 181,\n",
       " 'min_data_in_leaf': 61,\n",
       " 'min_sum_hessian_in_leaf': 4.792414358623587e-05,\n",
       " 'feature_fraction': 0.7756573845414456,\n",
       " 'bagging_fraction': 0.8597344848927815,\n",
       " 'lambda_l1': 0.49252223377910603,\n",
       " 'lambda_l2': 83.76388146302452,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metrics': 'auc',\n",
       " 'learning_rate': 0.02,\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_freq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ce696a8-3d8d-4505-953f-22db26706fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train = pd.read_csv('./train.csv')\n",
    "x_train_lr = lr_train[['Pclass', 'Age', 'Embarked']]\n",
    "y_train_lr = lr_train[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9656a3eb-32a3-418a-88aa-c16418f291b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 3), (891, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lr.shape, y_train_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a937327-d329-4859-b143-2f1e230fc046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lr['Age'] = x_train_lr['Age'].fillna(x_train_lr['Age'].mean())\n",
    "x_train_lr['Embarked'] = x_train_lr['Embarked'].fillna(x_train_lr['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bceba459-2be6-41ea-938c-1892e73862ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train_lr[['Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97aed523-8525-452a-8ad1-429c5b955500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0.0         0.0         1.0\n",
       "1           1.0         0.0         0.0\n",
       "2           0.0         0.0         1.0\n",
       "3           0.0         0.0         1.0\n",
       "4           0.0         0.0         1.0\n",
       "..          ...         ...         ...\n",
       "886         0.0         0.0         1.0\n",
       "887         0.0         0.0         1.0\n",
       "888         0.0         0.0         1.0\n",
       "889         1.0         0.0         0.0\n",
       "890         0.0         1.0         0.0\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embarked = pd.DataFrame(ohe.transform(x_train_lr[['Embarked']]).toarray(),\n",
    "                            columns=['Embarked_{}'.format(col) for col in ohe.categories_[0]])\n",
    "df_embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3eb08cd5-af93-4408-b56e-26042c18be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass        Age  Embarked_C  Embarked_Q  Embarked_S\n",
       "0         3  22.000000         0.0         0.0         1.0\n",
       "1         1  38.000000         1.0         0.0         0.0\n",
       "2         3  26.000000         0.0         0.0         1.0\n",
       "3         1  35.000000         0.0         0.0         1.0\n",
       "4         3  35.000000         0.0         0.0         1.0\n",
       "..      ...        ...         ...         ...         ...\n",
       "886       2  27.000000         0.0         0.0         1.0\n",
       "887       1  19.000000         0.0         0.0         1.0\n",
       "888       3  29.699118         0.0         0.0         1.0\n",
       "889       1  26.000000         1.0         0.0         0.0\n",
       "890       3  32.000000         0.0         1.0         0.0\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lr = pd.concat([x_train_lr, df_embarked], axis=1)\n",
    "x_train_lr = x_train_lr.drop(columns=['Embarked'])\n",
    "x_train_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8af4a159-a7c1-4385-b864-acf0ab4d11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lr['Pclass'] = (x_train_lr['Pclass'] - x_train_lr['Pclass'].min()) / (x_train_lr['Pclass'].max() - x_train_lr['Pclass'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48e763af-c871-4c1e-84bd-e1b16f15a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lr['Age'] = (x_train_lr['Age'] - x_train_lr['Age'].min()) / (x_train_lr['Age'].max() - x_train_lr['Age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6785b752-aa52-4c90-9f04-f75ee861ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train_lr, y_train_lr, test_size=0.2, stratify=y_train_lr, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a759cfd-682c-4423-92ca-6be5ce5aa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7262569832402235\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logis = LogisticRegression()\n",
    "\n",
    "model_logis.fit(x_tr, y_tr)\n",
    "\n",
    "y_va_pred = model_logis.predict(x_va)\n",
    "print(accuracy_score(y_va, y_va_pred))\n",
    "print(y_va_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9776b86-cfa5-4ec3-863f-c3ca64adcb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7150837988826816\n",
      "[0 1 0 1 0]\n",
      "[[0.73990307 0.26009693]\n",
      " [0.28229766 0.71770234]\n",
      " [0.73990072 0.26009928]\n",
      " [0.2682028  0.7317972 ]\n",
      " [0.58944465 0.41055535]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC(C=1.0, random_state=123, probability=True)\n",
    "model_svm.fit(x_tr, y_tr)\n",
    "\n",
    "y_va_pred = model_svm.predict(x_va)\n",
    "print(accuracy_score(y_va, y_va_pred))\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "y_va_pred_prob = model_svm.predict_proba(x_va)\n",
    "print(y_va_pred_prob[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83578659-b8b4-43b3-b161-85a7f13d0c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
